{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/chenzhiwei/Downloads/麻醉/麻醉学-第3版杨拔贤/2024_07_09_002a177993bd97d1d6d7g/2024_07_09_002a177993bd97d1d6d7g.tex'\n",
    "with open(file, 'r') as f:\n",
    "    tex_content = f.read()\n",
    "\n",
    "def split_tex_by_section(tex_content):\n",
    "    sections = re.split('\\\\\\\\section\\*', tex_content)\n",
    "    # sections = ['\\section*' + sec for sec in sections if sec]\n",
    "    sections = [section.replace('\\n', ' ').replace('\\\\', ' ') for section in sections]\n",
    "    return sections\n",
    "def make_datasets(sections):\n",
    "    datasets = []\n",
    "    current_set = \"\"\n",
    "    current_len = 0\n",
    "\n",
    "    for section in sections:\n",
    "        section_len = len(section)\n",
    "        \n",
    "        if section_len + current_len < 5000:\n",
    "            current_set += section\n",
    "            current_len += section_len\n",
    "        else:\n",
    "            if section_len >= 5000:\n",
    "                # 将超长的section拆分为多个部分\n",
    "                while len(section) >= 5000:\n",
    "                    datasets.append(section[:4999])\n",
    "                    section = section[4799:] # 允许 100 个重合\n",
    "                current_set = section\n",
    "                current_len = len(section)\n",
    "            else:\n",
    "                datasets.append(current_set)\n",
    "                current_set = section\n",
    "                current_len = section_len\n",
    "\n",
    "    if current_set:\n",
    "        datasets.append(current_set)\n",
    "\n",
    "    return datasets\n",
    "\n",
    "# def make_datasets(sections):\n",
    "#     datasets = []\n",
    "#     current_set = \" \"\n",
    "#     current_len = 0\n",
    "\n",
    "#     for section in sections:\n",
    "#         if len(section) + current_len < 5000:\n",
    "#             current_set += str(section)\n",
    "#             current_len += len(section)\n",
    "#         else:\n",
    "#             datasets.append(current_set)\n",
    "#             current_set = \" \" + section\n",
    "#             current_len = len(section)\n",
    "\n",
    "#     if current_set:\n",
    "#         datasets.append(current_set)\n",
    "\n",
    "#     return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677\n"
     ]
    }
   ],
   "source": [
    "sections = split_tex_by_section(tex_content)\n",
    "print(len(sections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6267\n",
      "5168\n"
     ]
    }
   ],
   "source": [
    "for section in sections:\n",
    "    if len(section) > 5000:\n",
    "        print(len(section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = make_datasets(sections)\n",
    "for dataset in datasets:\n",
    "    if len(dataset) > 4999:\n",
    "        print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999\n"
     ]
    }
   ],
   "source": [
    "max = -1 \n",
    "for dataset in datasets:\n",
    "    max = max if max > len(dataset) else len(dataset)\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def save_datasets_to_dataframe(datasets):\n",
    "    rows = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        rows.append({\"cn\": dataset, \"en\": None})\n",
    "        # add dataset to df new row: 'cn': dataset, 'en': None \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_pickle(\"dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_datasets_to_dataframe(datasets)\n",
    "import pandas as pd\n",
    "local_df = pd.read_pickle('dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cn</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>% This LaTeX document needs to be compiled wit...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{本次修订和编写特点如下:}  begin{enumerate}    item 教材编写修...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{刘 进} 男, 主任医师,教授,博士研究生导师。1956 年 8 月生于湖北省恩施市。现任...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  cn    en\n",
       "0  % This LaTeX document needs to be compiled wit...  None\n",
       "1  {本次修订和编写特点如下:}  begin{enumerate}    item 教材编写修...  None\n",
       "2  {刘 进} 男, 主任医师,教授,博士研究生导师。1956 年 8 月生于湖北省恩施市。现任...  None"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for index,row in local_df.iterrows():\n",
    "    if (row['en'] == None ):\n",
    "        print(\"True\")\n",
    "        # row['en'] = None\n",
    "        # local_df.to_pickle(\"dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'darwin'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "sys.platform"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyautogui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
