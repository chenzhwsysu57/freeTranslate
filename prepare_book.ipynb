{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 麻醉学-第3版杨拔贤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/chenzhiwei/Downloads/麻醉/麻醉学-第3版杨拔贤/2024_07_09_002a177993bd97d1d6d7g/2024_07_09_002a177993bd97d1d6d7g.tex'\n",
    "with open(file, 'r') as f:\n",
    "    tex_content = f.read()\n",
    "\n",
    "def split_tex_by_section(tex_content):\n",
    "    sections = re.split('\\\\\\\\section\\*', tex_content)\n",
    "    # sections = ['\\section*' + sec for sec in sections if sec]\n",
    "    sections = [section.replace('\\n', ' ').replace('\\\\', ' ') for section in sections]\n",
    "    return sections\n",
    "def make_datasets(sections):\n",
    "    datasets = []\n",
    "    current_set = \"\"\n",
    "    current_len = 0\n",
    "\n",
    "    for section in sections:\n",
    "        section_len = len(section)\n",
    "        \n",
    "        if section_len + current_len < 5000:\n",
    "            current_set += section\n",
    "            current_len += section_len\n",
    "        else:\n",
    "            if section_len >= 5000:\n",
    "                # 将超长的section拆分为多个部分\n",
    "                while len(section) >= 5000:\n",
    "                    datasets.append(section[:4999])\n",
    "                    section = section[4799:] # 允许 100 个重合\n",
    "                current_set = section\n",
    "                current_len = len(section)\n",
    "            else:\n",
    "                datasets.append(current_set)\n",
    "                current_set = section\n",
    "                current_len = section_len\n",
    "\n",
    "    if current_set:\n",
    "        datasets.append(current_set)\n",
    "\n",
    "    return datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677\n"
     ]
    }
   ],
   "source": [
    "sections = split_tex_by_section(tex_content)\n",
    "print(len(sections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6267\n",
      "5168\n"
     ]
    }
   ],
   "source": [
    "for section in sections:\n",
    "    if len(section) > 5000:\n",
    "        print(len(section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = make_datasets(sections)\n",
    "for dataset in datasets:\n",
    "    if len(dataset) > 4999:\n",
    "        print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999\n"
     ]
    }
   ],
   "source": [
    "max = -1 \n",
    "for dataset in datasets:\n",
    "    max = max if max > len(dataset) else len(dataset)\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def save_datasets_to_dataframe(datasets):\n",
    "    rows = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        rows.append({\"cn\": dataset, \"en\": None})\n",
    "        # add dataset to df new row: 'cn': dataset, 'en': None \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_pickle(\"dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_datasets_to_dataframe(datasets)\n",
    "import pandas as pd\n",
    "local_df = pd.read_pickle('dataset.pkl')\n",
    "for index,row in local_df.iterrows():\n",
    "    if (row['en'] != None  ):\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'darwin'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "sys.platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 麻醉学高级教程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2078\n",
      "17602\n",
      "6750\n",
      "7484\n",
      "5216\n",
      "5457\n",
      "6131\n",
      "5546\n",
      "8226\n",
      "7366\n",
      "5930\n",
      "5864\n",
      "6402\n",
      "9573\n",
      "11468\n",
      "5980\n",
      "5779\n",
      "5999\n",
      "7577\n",
      "5222\n",
      "5861\n",
      "9114\n",
      "6457\n",
      "5363\n",
      "7487\n",
      "7578\n",
      "6642\n",
      "9396\n",
      "5258\n",
      "5901\n",
      "5551\n",
      "7544\n",
      "5456\n",
      "7603\n",
      "7159\n",
      "8342\n",
      "7743\n"
     ]
    }
   ],
   "source": [
    "file = '/Users/chenzhiwei/Downloads/麻醉/麻醉学高级教程/2024_07_10_373f31b88d2bf633007bg/2024_07_10_373f31b88d2bf633007bg.tex'\n",
    "with open(file, 'r') as f:\n",
    "    tex_content = f.read()\n",
    "def split_tex_by_section(tex_content):\n",
    "    sections = re.split('\\\\\\\\section\\*', tex_content)\n",
    "    # sections = ['\\section*' + sec for sec in sections if sec]\n",
    "    sections = [section.replace('\\n', ' ').replace('\\\\', ' ') for section in sections]\n",
    "    return sections\n",
    "def make_datasets(sections):\n",
    "    datasets = []\n",
    "    current_set = \"\"\n",
    "    current_len = 0\n",
    "\n",
    "    for section in sections:\n",
    "        section_len = len(section)\n",
    "        \n",
    "        if section_len + current_len < 5000:\n",
    "            current_set += section\n",
    "            current_len += section_len\n",
    "        else:\n",
    "            if section_len >= 5000:\n",
    "                # 将超长的section拆分为多个部分\n",
    "                while len(section) >= 5000:\n",
    "                    datasets.append(section[:4999])\n",
    "                    section = section[4799:] # 允许 100 个重合\n",
    "                current_set = section\n",
    "                current_len = len(section)\n",
    "            else:\n",
    "                datasets.append(current_set)\n",
    "                current_set = section\n",
    "                current_len = section_len\n",
    "\n",
    "    if current_set:\n",
    "        datasets.append(current_set)\n",
    "\n",
    "    return datasets\n",
    "sections = split_tex_by_section(tex_content)\n",
    "print(len(sections))\n",
    "for section in sections:\n",
    "    if len(section) > 5000:\n",
    "        print(len(section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999\n",
      "352\n"
     ]
    }
   ],
   "source": [
    "datasets = make_datasets(sections)\n",
    "for dataset in datasets:\n",
    "    if len(dataset) > 4999:\n",
    "        print(len(dataset))\n",
    "max = -1 \n",
    "for dataset in datasets:\n",
    "    max = max if max > len(dataset) else len(dataset)\n",
    "print(max)\n",
    "print(len(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def save_datasets_to_dataframe(datasets):\n",
    "    rows = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        rows.append({\"cn\": dataset, \"en\": None})\n",
    "        # add dataset to df new row: 'cn': dataset, 'en': None \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_pickle(\"麻醉学高级教程.pkl\")\n",
    "save_datasets_to_dataframe(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "local_df = pd.read_pickle('麻醉学高级教程.pkl')\n",
    "for index,row in local_df.iterrows():\n",
    "    if (row['en'] != None  ):\n",
    "        print(index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyautogui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
